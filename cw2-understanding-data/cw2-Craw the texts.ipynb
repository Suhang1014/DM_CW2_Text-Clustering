{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining cw2 - Understanding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_by_bs(doc_text):\n",
    "    \"\"\"提取html页面的所有文本信息。\n",
    "    参考：\n",
    "    http://stackoverflow.com/questions/328356/extracting-text-from-html-file-using-python\n",
    "    \"\"\"\n",
    "    title, text = '', ''\n",
    "    soup = BeautifulSoup(doc_text, 'lxml')\n",
    "    try:\n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.extract()\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "            # get text\n",
    "            title = soup.title.string\n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            pass\n",
    "        text = soup.get_text()\n",
    "        lines = (line.strip() for line in text.splitlines())\n",
    "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "        text = ' '.join(chunk for chunk in chunks if chunk)\n",
    "    return title, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = '/Users/suhang/Documents/GitHub/COMP6237-Data-Mining/cw2-understanding-data/gap-html'\n",
    "titles = []\n",
    "texts = []\n",
    "folders = os.listdir(rootdir)\n",
    "for folder in folders:\n",
    "    if folder != '.DS_Store':\n",
    "        folder_path = os.path.join(rootdir, folder)\n",
    "        files = os.listdir(folder_path)\n",
    "        for file in files:\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            if os.path.isfile(file_path):\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    this_title, this_text = extract_text_by_bs(f)\n",
    "                    titles.append(this_title)\n",
    "                    texts.append(this_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(texts)):\n",
    "    file_name = '/Users/suhang/Documents/GitHub/COMP6237-Data-Mining/cw2-understanding-data/raw_text/0000000' + str(i+1) + '.txt'\n",
    "    raw_text = texts[i]\n",
    "    with open(file_name, 'w') as f:\n",
    "        f.write(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_file_name = '/Users/suhang/Documents/GitHub/COMP6237-Data-Mining/cw2-understanding-data/raw_text/whole_text.txt'\n",
    "with open(whole_file_name, 'w') as f:\n",
    "    for i in range(0, len(texts)):\n",
    "        f.write('File ' + str(i+1) + ':\\n')\n",
    "        f.write(texts[i])\n",
    "        f.write('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
